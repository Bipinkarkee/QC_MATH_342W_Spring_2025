adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
#train on train set
svm_mod = svm(income ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$income = ifelse(adult$income == ">50K", 1, 0)
n = 8000
set.seed(1)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
#train on train set
svm_mod = svm(income ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$income = ifelse(adult$income == ">50K", 1, 0)
n = 8000
set.seed(2)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
#train on train set
svm_mod = svm(income ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$income = ifelse(adult$income == ">50K", 1, 0)
n = 5000
set.seed(2)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
#train on train set
svm_mod = svm(income ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$income = ifelse(adult$income == ">50K", 1, 0)
n = 5000
set.seed(3))
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$income = ifelse(adult$income == ">50K", 1, 0)
n = 5000
set.seed(3)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
#train on train set
svm_mod = svm(income ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$native_country = NULL
adult$income = ifelse(adult$income == ">50K", 1, 0)
n = 5000
set.seed(3)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
#train on train set
svm_mod = svm(income ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
ggplot(data.frame(cost = cost_grid, miscl_err = select_set_misclassification_errors_by_m)) +
aes(x = cost, y = miscl_err) +
geom_line(color = "grey") +
geom_point(lwd = 3) +
scale_x_log10()
y_hat
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$native_country = NULL
# adult$income = ifelse(adult$income == ">50K", 1, 0)
n = 5000
set.seed(3)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
#train on train set
svm_mod = svm(income ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
head(y_hat)
mean(adult_select$income != y_hat)
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$native_country = NULL
adult$income = factor(adult$income)
n = 5000
set.seed(3)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
ggplot(data.frame(cost = cost_grid, miscl_err = select_set_misclassification_errors_by_m)) +
aes(x = cost, y = miscl_err) +
geom_line(color = "grey") +
geom_point(lwd = 3) +
scale_x_log10()
M = 50
cost_grid = 10^seq(from = -5, to = 3, length.out = M)
cost_grid
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
ggplot(data.frame(cost = cost_grid, miscl_err = select_set_misclassification_errors_by_m)) +
aes(x = cost, y = miscl_err) +
geom_line(color = "grey") +
geom_point(lwd = 3) +
scale_x_log10()
M = 30
cost_grid = 10^seq(from = -5, to = 4, length.out = M)
cost_grid
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
ggplot(data.frame(cost = cost_grid, miscl_err = select_set_misclassification_errors_by_m)) +
aes(x = cost, y = miscl_err) +
geom_line(color = "grey") +
geom_point(lwd = 3) +
scale_x_log10()
M = 30
cost_grid = 10^seq(from = -3, to = 6, length.out = M)
cost_grid
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
ggplot(data.frame(cost = cost_grid, miscl_err = select_set_misclassification_errors_by_m)) +
aes(x = cost, y = miscl_err) +
geom_line(color = "grey") +
geom_point(lwd = 3) +
scale_x_log10()
M = 30
cost_grid = 10^seq(from = -3, to = 5, length.out = M)
cost_grid
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
?svm
?svm.default
svm.default
MAX_NUM_ITER =
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m], scale = TRUE)
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
TOL = 0.01
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m], tolerance = TOL)
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
ggplot(data.frame(cost = cost_grid, miscl_err = select_set_misclassification_errors_by_m)) +
aes(x = cost, y = miscl_err) +
geom_line(color = "grey") +
geom_point(lwd = 3) +
scale_x_log10()
M = 30
cost_grid = 10^seq(from = -3, to = 5, length.out = M)
cost_grid
TOL = 0.01
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m], tolerance = TOL)
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
TOL = 0.1
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m], tolerance = TOL)
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$native_country = NULL
adult$income = factor(adult$income)
n = 3000
set.seed(3)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
M = 30
cost_grid = 10^seq(from = -3, to = 5, length.out = M)
cost_grid
TOL = 0.1
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m], tolerance = TOL)
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
ggplot(data.frame(cost = cost_grid, miscl_err = select_set_misclassification_errors_by_m)) +
aes(x = cost, y = miscl_err) +
geom_line(color = "grey") +
geom_point(lwd = 3) +
scale_x_log10()
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$native_country = NULL
adult$income = factor(adult$income)
n = 2000
set.seed(3)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
M = 30
cost_grid = 10^seq(from = -3, to = 4, length.out = M)
cost_grid
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$native_country = NULL
adult$income = factor(adult$income)
n = 2000
set.seed(1)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$native_country = NULL
adult$income = factor(adult$income)
n = 2000
set.seed(3)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$native_country = NULL
adult$income = factor(adult$income)
n = 2000
set.seed(4)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
pacman::p_load_gh("coatless/ucidata") #load from github
data(adult)
adult = na.omit(adult)
adult$native_country = NULL
adult$income = factor(adult$income)
n = 2000
set.seed(5)
adult = adult[sample(1 : nrow(adult), n), ]
adult_train =  adult[1 : (n / 3), ]
adult_select = adult[(n / 3 + 1) : (2 * n / 3), ]
adult_test =   adult[(2 * n / 3 + 1) : n, ]
select_set_misclassification_errors_by_m = array(NA, M)
for (m in 1 : M){
cat(m, "of", M, "\n")
#train on train set
svm_mod = svm(factor(income) ~ ., adult_train, kernel = "linear", cost = cost_grid[m])
#predict on select set
y_hat = predict(svm_mod, adult_select)
#measure error from the select set
select_set_misclassification_errors_by_m[m] = mean(adult_select$income != y_hat)
}
ggplot(data.frame(cost = cost_grid, miscl_err = select_set_misclassification_errors_by_m)) +
aes(x = cost, y = miscl_err) +
geom_line(color = "grey") +
geom_point(lwd = 3) +
scale_x_log10()
min(select_set_misclassification_errors_by_m)
optimal_cost_hyperparam = cost_grid[which.min(select_set_misclassification_errors_by_m)]
optimal_cost_hyperparam
svm_mod = svm(income ~ ., adult_train, kernel = "linear", cost = optimal_cost_hyperparam)
y_hat = predict(svm_mod, adult_test)
mean(adult_test$income != y_hat)
g_final = svm(income ~ ., adult, kernel = "linear", cost = optimal_cost_hyperparam)
rm(list = ls())
diamonds = ggplot2::diamonds
diamonds$cut = factor(diamonds$cut, ordered = FALSE)
diamonds$color = factor(diamonds$color, ordered = FALSE)
diamonds$clarity = factor(diamonds$clarity, ordered = FALSE)
Nsamp = 1300
set.seed(1984)
subindices = sample(1 : nrow(diamonds), Nsamp * 3)
diamonds_train = diamonds[subindices[1 : Nsamp], ]
diamonds_select = diamonds[subindices[(Nsamp + 1) : (2 * Nsamp)], ]
diamonds_test = diamonds[subindices[(2 * Nsamp + 1) : (3 * Nsamp)], ]
rm(subindices)
mod = lm(price ~ . * . * ., diamonds_train)
length(coef(mod))
sample(names(coef(mod)), 100)
summary(mod)$r.squared
sd(summary(mod)$residuals)
y_hat_test = predict(mod, diamonds_test)
y_test = diamonds_test$price
e_test = y_test - y_hat_test
1 - sum((e_test)^2) / sum((y_test - mean(y_test))^2)
sd(e_test)
sd(y_test)
sd(e_test) / sd(y_test)
Xmm_train = model.matrix(price ~ . * . * ., diamonds_train)
y_train = diamonds_train$price
p_plus_one = ncol(Xmm_train)
Xmm_select = model.matrix(price ~ . * . * ., diamonds_select)
y_select = diamonds_select$price
included_features_by_iter = c() #keep a growing list of predictors by iteration
in_sample_ses_by_iteration = c() #keep a growing list of se's by iteration
oos_ses_by_iteration = c() #keep a growing list of se's by iteration
i = 1
repeat {
#get all predictors left to try
all_ses = array(NA, p_plus_one) #record all possibilities
for (j_try in 1 : p_plus_one){
if (j_try %in% included_features_by_iter){
next
}
Xmm_sub = Xmm_train[, c(included_features_by_iter, j_try), drop = FALSE]
all_ses[j_try] = sd(lm.fit(Xmm_sub, y_train)$residuals) #lm.fit so much faster than lm!
}
j_star = which.min(all_ses)
included_features_by_iter = c(included_features_by_iter, j_star)
in_sample_ses_by_iteration = c(in_sample_ses_by_iteration, all_ses[j_star])
#now let's look at oos
Xmm_sub = Xmm_train[, included_features_by_iter, drop = FALSE]
mod = lm.fit(Xmm_sub, y_train)
y_hat_select = Xmm_select[, included_features_by_iter, drop = FALSE] %*% mod$coefficients
oos_se = sd(y_select - y_hat_select)
oos_ses_by_iteration = c(oos_ses_by_iteration, oos_se)
cat("i =", i, "in sample: se = ", round(all_ses[j_star], 1), "oos_se", round(oos_se, 1), "added:", colnames(Xmm_train)[j_star], "\n")
i = i + 1
if (i > Nsamp || i > p_plus_one){
break #why??
}
}
simulation_results = data.frame(
iteration = 1 : length(in_sample_ses_by_iteration),
in_sample_ses_by_iteration = in_sample_ses_by_iteration,
oos_ses_by_iteration = oos_ses_by_iteration
)
pacman::p_load(latex2exp)
ggplot(simulation_results) +
geom_line(aes(x = iteration, y = in_sample_ses_by_iteration), col = "red") +
geom_line(aes(x = iteration, y = oos_ses_by_iteration), col = "blue") +
ylim(0, max(c(simulation_results$in_sample_ses_by_iteration, simulation_results$oos_ses_by_iteration)))
ylab(TeX("$s_e$"))
p_opt = 41 #change this based on plot above
oos_ses_by_iteration[p_opt]
sort(colnames(Xmm_train)[included_features_by_iter[1 : p_opt]])
Xmm_test = model.matrix(price ~ . * . * ., diamonds_test)
optimal_mod = lm(diamonds_test$price ~ 0 + Xmm_test[, included_features_by_iter[1 : p_opt]])
summary(optimal_mod)$sigma
205.65/4470.91
