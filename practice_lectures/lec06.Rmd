---
title: "Practice Lecture 6 MATH 342W Queens College"
author: "Professor Adam Kapelner"
---

## Nearest Neighbor (NN) model

Load up the breast cancer data set again.

```{r}
rm(list = ls())
Xy = na.omit(MASS::biopsy) #The "breast cancer" data with all observations with missing values dropped
X = as.matrix(Xy[, 2 : 10]) #V1, V2, ..., V9
y_binary = as.numeric(Xy$class == "malignant")
```

Let's say we want to build a nearest neighbor model with the first covariate only. We are then looking for the label (response) of the closest x_1. Here is a simple function that does it:

```{r}
nn_function = function(x_star){
  y_binary[which.min((X[, 1] - x_star)^2)]
}
nn_function(7.8)
nn_function(5.2)
```

Why is this silly for this dataset?

```{r}
table(X[, 1])
```

The features are not truly continuous. Would it make sense in higher dimensions? Your homework...

Has this been coded before? Definitely...

```{r}
pacman::p_load(class)
?knn
```

The design of this function is not canonical. We fit a NN model *and* predict in one function via:

```{r}
y_hat = knn(X, c(4, 2, 1, 1, 2, 1, 2, 1, 1), y_binary, k = 1)
y_hat
```

Now for an interesting exercise that will setup future classes:

```{r}
y_hat = knn(X, X, y_binary, k = 1)
mean(y_hat != factor(y_binary))
```

No errors! Can this be a good model? No... "something" must be wrong! It is too good to be true.

Something is wrong. This is the first example of "overfitting". We will explore this later in depth (it is one of the core concepts of this course).

Let's see $K > 1$


```{r}
y_hat = knn(X, X, y_binary, k = 10)
mean(y_hat != factor(y_binary))
```

Why would there be difference now between predictions and the actual data?
