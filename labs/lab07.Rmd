---
title: "Lab 7"
author: "Your Name Here"
output: pdf_document
---




#Visualization with the package ggplot2

I highly recommend using the [ggplot cheat sheet](https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf) as a reference resource. You will see questions that say "Create the best-looking plot". Among other things you may choose to do, remember to label the axes using real English, provide a title and subtitle. You may want to pick a theme and color scheme that you like and keep that constant throughout this lab. The default is fine if you are running short of time.

Load up the `GSSvocab` dataset in package `carData` as `X` and drop all observations with missing measurements. This will be a very hard visualization exercise since there is not a good model for vocab.

```{r}
#TO-DO
```

Briefly summarize the documentation on this dataset. What is the data type of each variable? What do you think is the response variable the collectors of this data had in mind?

#TO-DO

Create two different plots and identify the best-looking plot you can to examine the `age` variable. Save the best looking plot as an appropriately-named PDF.

```{r}
#TO-DO
```

Create two different plots and identify the best looking plot you can to examine the `vocab` variable. Save the best looking plot as an appropriately-named PDF.

```{r}
#TO-DO
```

Create the best-looking plot you can to examine the `ageGroup` variable by `gender`. Does there appear to be an association? There are many ways to do this.

```{r}
#TO-DO
```

Create the best-looking plot you can to examine the `vocab` variable by `age`. Does there appear to be an association?

```{r}
#TO-DO
```

Add an estimate of $f(x)$ using the smoothing geometry to the previous plot. Does there appear to be an association now?

```{r}
#TO-DO
```

Using the plot from the previous question, create the best looking plot overloading with variable `gender`. Does there appear to be an interaction of `gender` and `age`?

```{r}
#TO-DO
```


Using the plot from the previous question, create the best looking plot overloading with variable `nativeBorn`. Does there appear to be an interaction of `nativeBorn` and `age`?

```{r}
#TO-DO
```

Create two different plots and identify the best-looking plot you can to examine the `vocab` variable by `educGroup`. Does there appear to be an association?

```{r}
#TO-DO
```

Using the best-looking plot from the previous question, create the best looking overloading with variable `gender`. Does there appear to be an interaction of `gender` and `educGroup`?

```{r}
#TO-DO
```

Using facets, examine the relationship between `vocab` and `ageGroup`. You can drop year level `(Other)`. Are we getting dumber?

```{r}
#TO-DO
```

#Rcpp and optimizing R

Write a function `dot_product_R` in R that takes in two vectors `v1` and `v2` and returns their dot product.

```{r}
#TO-DO
```

Write a function `dot_product_cpp` in C++ and make sure it compiles.

```{r}
cppFunction('
  double dot_product_cpp(NumericVector v1, NumericVector v2) {
    #TO-DO
  }
')
```

Create two vectors of standard normal realizations with length `n=1e6` and test the different in speed.

```{r}
n = 1e6
v1 = rnorm(n)
v2 = rnorm(n)

pacman::p_load(microbenchmark)
microbenchmark(
  dot_product_R(v1, v2), 
  dot_product_cpp(v1, v2),
  times = 10
)
```

Implement the Gram Schmidt routine as a C++ function `gram_schmidt_cpp`.

```{r}
#TO-DO
```

Here is the implementation in R for reference taken from lab 5:

```{r}
gram_schmidt_R = function(X){
  #first create orthogonal matrix
  V = matrix(NA, nrow = nrow(X), ncol = ncol(X))
  V[, 1] = X[, 1]
  
  for (j in 2 : ncol(X)){
    V[, j] = X[, j]
    
    for (k in 1 : (j-1)){
      v_k = V[, k, drop = FALSE]
      V[, j] = V[, j, drop = FALSE] - (t(t(v_k)) %*% t(v_k) / sum(v_k^2)) %*% t(t(X[, j])) #i.e. the orthogonal projection of X[, j] onto v_k
    }
  }
  
  Q = matrix(NA, nrow = nrow(X), ncol = ncol(X))
  for (j in 1 : ncol(X)){
    Q[, j] = V[, j] / sqrt(sum(V[, j]^2))
  }
  Q
}
```

Now let's see how much faster C++ is by running it on the boston housing data design matrix
```{r}
X = model.matrix(medv ~ ., MASS::Boston)

microbenchmark(
  gram_schmidt_R(X),
  gram_schmidt_cpp(X),
  times = 10
)
```

Create a variable `n` to be 10 and a vaiable `Nvec` to be 100 initially. Create a random vector via `rnorm` `Nvec` times and load it into a `Nvec` x `n` dimensional matrix.

```{r}
#TO-DO
```

Write a function `all_angles` that measures the angle between each of the pairs of vectors. You should measure the vector on a scale of 0 to 180 degrees with negative angles coerced to be positive.

```{r}
#TO-DO
```

Plot the density of these angles.

```{r}
#TO-DO
```

Write an Rcpp function `all_angles_cpp` that does the same thing. Use an IDE if you want, but write it below in-line.

```{r}
#TO-DO
```

Test the time difference between these functions for `n = 1000` and `Nvec = 100, 500, 1000, 5000` using the package `microbenchmark`.  Store the results in a matrix with rows representing `Nvec` and two columns for base R and Rcpp.

```{r}
Nvecs = c(100, 500, 1000, 5000)

results_for_time = data.frame(
  Nvec = Nvecs,
  time_for_base_R = numeric(),
  time_for_cpp = numeric()
)
for (i in 1 : length(Nvecs)){
  X = matrix(rnorm(n * Nvecs[i]), nrow = Nvec)
  results_for_time$time_for_base_R[i] = all_angles(X)
  results_for_time$time_for_cpp[i] = all_angles_cpp(X)
}

ggplot(results_for_time) + 
  geom_line(aes(x = Nvec, y = time_for_base_R), col = "red") +
  geom_line(aes(x = Nvec, y = time_for_cpp), col = "blue")
```

Plot the divergence of performance (in log seconds) over n using a line geometry. Use two different colors for the R and CPP functions. Make sure there's a color legend on your plot. We wil see later how to create "long" matrices that make such plots easier.

```{r}
#TO-DO
```

Let `Nvec = 10000` and vary `n` to be 10, 100, 1000. Plot the density of angles for all three values of `n` on one plot using color to signify `n`. Make sure you have a color legend. This is not easy.

```{r}
#TO-DO
```

Write an R function `nth_fibonnaci` that finds the nth Fibonnaci number via recursion but allows you to specify the starting number. For instance, if the sequence started at 1, you get the familiar 1, 1, 2, 3, 5, etc. But if it started at 0.01, you would get 0.01, 0.01, 0.02, 0.03, 0.05, etc.

```{r}
#TO-DO
```

Write an Rcpp function `nth_fibonnaci_cpp` that does the same thing. Use an IDE if you want, but write it below in-line.

```{r}
#TO-DO
```

Time the difference in these functions for n = 100, 200, ...., 1500 while starting the sequence at the smallest possible floating point value in R. Store the results in a matrix.

```{r}
#TO-DO
```

Plot the divergence of performance (in log seconds) over n using a line geometry. Use two different colors for the R and CPP functions. Make sure there's a color legend on your plot.

```{r}
#TO-DO
```
