---
title: "Lab 9"
author: "Your Name Here"
output: pdf_document
---


#Rcpp and optimizing R

Write a function `dot_product_R` in R that takes in two vectors `v1` and `v2` and returns their dot product.

```{r}
#TO-DO
```

Write a function `dot_product_cpp` in C++ and make sure it compiles.

```{r}
cppFunction('
  double dot_product_cpp(NumericVector v1, NumericVector v2) {
    #TO-DO
  }
')
```

Create two vectors of standard normal realizations with length `n=1e6` and test the different in speed.

```{r}
n = 1e6
v1 = rnorm(n)
v2 = rnorm(n)

pacman::p_load(microbenchmark)
microbenchmark(
  dot_product_R(v1, v2), 
  dot_product_cpp(v1, v2),
  times = 10
)
```

Implement the Gram Schmidt routine as a C++ function `gram_schmidt_cpp`.

```{r}
#TO-DO
```

Here is the implementation in R for reference taken from lab 5:

```{r}
gram_schmidt_R = function(X){
  #first create orthogonal matrix
  V = matrix(NA, nrow = nrow(X), ncol = ncol(X))
  V[, 1] = X[, 1]
  
  for (j in 2 : ncol(X)){
    V[, j] = X[, j]
    
    for (k in 1 : (j-1)){
      v_k = V[, k, drop = FALSE]
      V[, j] = V[, j, drop = FALSE] - (t(t(v_k)) %*% t(v_k) / sum(v_k^2)) %*% t(t(X[, j])) #i.e. the orthogonal projection of X[, j] onto v_k
    }
  }
  
  Q = matrix(NA, nrow = nrow(X), ncol = ncol(X))
  for (j in 1 : ncol(X)){
    Q[, j] = V[, j] / sqrt(sum(V[, j]^2))
  }
  Q
}
```

Now let's see how much faster C++ is by running it on the boston housing data design matrix
```{r}
X = model.matrix(medv ~ ., MASS::Boston)

microbenchmark(
  gram_schmidt_R(X),
  gram_schmidt_cpp(X),
  times = 10
)
```

Create a variable `n` to be 10 and a variable `Nvec` to be 100 initially. Create a random vector via `rnorm` `Nvec` times and load it into a `Nvec` x `n` dimensional matrix.

```{r}
#TO-DO
```

Write a function `all_angles` that measures the angle between each of the pairs of the `Nvec` vectors. You should measure the vector on a scale of 0 to 180 degrees with negative angles coerced to be positive.

```{r}
#TO-DO
```

Plot the density of these angles.

```{r}
#TO-DO
```

Write an Rcpp function `all_angles_cpp` that does the same thing. Use an IDE if you want, but write it below in-line.

```{r}
#TO-DO
```

Test the time difference between these functions for `n = 1000` and `Nvec = 100, 500, 1000, 5000` using the package `microbenchmark`.  Store the results in a matrix with rows representing `Nvec` and two columns for base R and Rcpp.

```{r}
Nvecs = c(100, 500, 1000, 5000)

results_for_time = data.frame(
  Nvec = Nvecs,
  time_for_base_R = numeric(),
  time_for_cpp = numeric()
)
for (i in 1 : length(Nvecs)){
  X = matrix(rnorm(n * Nvecs[i]), nrow = Nvec)
  results_for_time$time_for_base_R[i] = all_angles(X)
  results_for_time$time_for_cpp[i] = all_angles_cpp(X)
}

ggplot(results_for_time) + 
  geom_line(aes(x = Nvec, y = time_for_base_R), col = "red") +
  geom_line(aes(x = Nvec, y = time_for_cpp), col = "blue")
```

Plot the divergence of performance (in log seconds) over n using a line geometry. Use two different colors for the R and CPP functions. Make sure there's a color legend on your plot. We wil see later how to create "long" matrices that make such plots easier.

```{r}
#TO-DO
```

Let `Nvec = 10000` and vary `n` to be 10, 100, 1000. Plot the density of angles for all three values of `n` on one plot using color to signify `n`. Make sure you have a color legend. This is not easy.

```{r}
#TO-DO
```

Write an R function `nth_fibonnaci` that finds the nth Fibonnaci number via recursion but allows you to specify the starting number. For instance, if the sequence started at 1, you get the familiar 1, 1, 2, 3, 5, etc. But if it started at 0.01, you would get 0.01, 0.01, 0.02, 0.03, 0.05, etc.

```{r}
#TO-DO
```

Write an Rcpp function `nth_fibonnaci_cpp` that does the same thing. Use an IDE if you want, but write it below in-line.

```{r}
#TO-DO
```

Time the difference in these functions for n = 100, 200, ...., 1500 while starting the sequence at the smallest possible floating point value in R. Store the results in a matrix.

```{r}
#TO-DO
```

Plot the divergence of performance (in log seconds) over n using a line geometry. Use two different colors for the R and CPP functions. Make sure there's a color legend on your plot.

```{r}
#TO-DO
```


#YARF setup

For the next couple of labs, I want you to make some use of a package I wrote that offers convenient and flexible tree-building and random forest-building. Make sure you have a JDK installed first

https://www.oracle.com/java/technologies/downloads/

Then try to install rJava

```{r}
options(java.parameters = "-Xmx4000m")
pacman::p_load(rJava)
.jinit()
```

If you have error, messages, try to google them. Everyone has trouble with rJava!

If that worked, please try to run the following which will install YARF from my github:

```{r}
if (!pacman::p_isinstalled(YARF)){
  pacman::p_install_gh("kapelner/YARF/YARFJARs", ref = "dev")
  pacman::p_install_gh("kapelner/YARF/YARF", ref = "dev", force = TRUE)
}
pacman::p_load(YARF)
```

Please try to fix the error messages (if they exist) as best as you can. I can help on slack.



# Regression Trees

You can use the `YARF` package if it works, otherwise, use the `randomForest` package (the canonical R package for this algorithm).

Let's take a look at a simulated sine curve. Below is the code for the data generating process:

```{r}
rm(list = ls())
n_train = 500
sigma = 0.3
x_min = 0
x_max = 10
x = runif(n_train, x_min, x_max)

f_x = function(x){sin(x)}
x_train = runif(n_train, x_min, x_max)
y_train = f_x(x) + rnorm(n_train, 0, sigma)
```

Plot an example dataset of size 500:

```{r}
n_test = 500
#TO-DO
```

Create a test set of size 500 from this data generating process:

```{r}
#TO-DO
```

Locate the optimal node size hyperparameter for the regression tree model. I believe you can use `randomForest` here by setting `ntree = 1`, `replace = FALSE`, `sampsize = n` (`mtry` is already set to be 1 because there is only one feature) and then you can set `nodesize`. Plot nodesize by out of sample s_e. Plot.

```{r}
#TO-DO
```

Plot the regression tree model g(x) with the optimal node size.

```{r}
#TO-DO
```

Find the oosRMSE of this optimal-node-size model.

```{r}
#TO-DO
```

